{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8aabb159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(os.path.join(\"..\", \".env\"), override=True)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a407e4",
   "metadata": {},
   "source": [
    "## Context Offloading: Filesystem\n",
    "\n",
    "<img src=\"./assets/agent_header_files.png\" width=\"800\" style=\"display:block; margin-left:0;\">\n",
    "\n",
    "Agent context windows can grow rapidly during complex tasks—the average Manus task uses approximately 50 tool calls, creating substantial context accumulation. A powerful technique for managing this growth is **context offloading** through filesystem operations. Rather than storing all tool call observations and intermediate results directly in the context window, agents can strategically save information to files and [fetch it as-needed](https://blog.langchain.com/context-engineering-for-agents/), maintaining focus while preserving access to critical information.\n",
    "\n",
    "This approach has been successfully implemented by production systems like [Manus](https://manus.im/blog/Context-Engineering-for-AI-Agents-Lessons-from-Building-Manus) and [Hugging Face Open Deep Research](https://huggingface.co/blog/open-deep-research). Anthropic's [multi-agent research system](https://www.anthropic.com/engineering/multi-agent-research-system#:~:text=Subagent%20output%20to%20a%20filesystem%20to%20minimize%20the%20%E2%80%98game%20of%20telephone.%E2%80%99) provides another compelling example, where subagents store their work in external systems and pass lightweight references back to coordinators. This prevents the \"game of telephone\" effect—information degradation as it passes through multiple agents—while enabling fresh subagents to spawn with clean contexts and retrieve stored context like research plans from memory when needed.\n",
    "\n",
    "By writing token-heavy context to files in sandboxed environments, agents can effectively manage memory while maintaining the ability to retrieve detailed information when necessary. This pattern is particularly valuable for structured outputs like code, reports, or data visualizations where specialized prompts produce better results than filtering through general coordinators, and for long-running research tasks where intermediate results need preservation without constant attention."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9854e27-f800-4563-9ed1-82837039cf97",
   "metadata": {},
   "source": [
    "### File Tools\n",
    "\n",
    "Our implementation uses a virtual filesystem approach that mocks the traditional filesystem within LangGraph state. The core insight is to use a simple dictionary where keys represent mock file paths and values contain the file content. This approach provides short-term, thread-wise persistence that's ideal for maintaining context within a single agent conversation, though it's not suited for information that needs to persist across different conversation threads. The file operations utilize LangGraph's `Command` type to update the agent state, enabling tools to modify the virtual filesystem and maintain proper state management throughout the agent's execution.\n",
    "\n",
    "You’ll build three file tools—`ls`, `read_file`, and `write_file`—that operate on the virtual file system.\n",
    "\n",
    "**Usage:** \n",
    "- When the LLM has information in its context that it wants to persist, it writes it to a file with `write_file`; later, the same agent or a subagent can retrieve it with `read_file`.\n",
    "- A tool call can write data to a file and provide the filename in the tool call return message to the LLM. The LLM can later decide to read some or all of the content, or could apply another tool to process the data. \n",
    "- Use `ls` to list available files.\n",
    "\n",
    "The read/write tools expect newline-delimited plain text (parsed with `str.splitlines()`).\n",
    "\n",
    "\n",
    "The descriptions in the prompts below describe in detail how they operate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "abe282a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  List all files in the virtual filesystem stored in agent state.                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Shows what files currently exist in agent memory. Use this to orient yourself before other file operations     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  and maintain awareness of your file organization.                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  No parameters required - simply call ls() to see all available files.                                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  List all files in the virtual filesystem stored in agent state.                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Shows what files currently exist in agent memory. Use this to orient yourself before other file operations     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  and maintain awareness of your file organization.                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  No parameters required - simply call ls() to see all available files.                                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils import show_prompt\n",
    "\n",
    "from deep_agents_from_scratch.prompts import (\n",
    "    LS_DESCRIPTION,\n",
    "    READ_FILE_DESCRIPTION,\n",
    "    WRITE_FILE_DESCRIPTION,\n",
    ")\n",
    "\n",
    "show_prompt(LS_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8dc7bb26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Read content from a file in the virtual filesystem with optional pagination.                                   <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  This tool returns file content with line numbers (like `cat -n`) and supports reading large files in chunks    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  to avoid context overflow.                                                                                     <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Parameters:                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - file_path (required): Path to the file you want to read                                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - offset (optional, default=0): Line number to start reading from                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - limit (optional, default=2000): Maximum number of lines to read                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Essential before making any edits to understand existing content. Always read a file before editing it.        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Read content from a file in the virtual filesystem with optional pagination.                                   \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  This tool returns file content with line numbers (like `cat -n`) and supports reading large files in chunks    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  to avoid context overflow.                                                                                     \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Parameters:                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - file_path (required): Path to the file you want to read                                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - offset (optional, default=0): Line number to start reading from                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - limit (optional, default=2000): Maximum number of lines to read                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Essential before making any edits to understand existing content. Always read a file before editing it.        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_prompt(READ_FILE_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2de27788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Create a new file or completely overwrite an existing file in the virtual filesystem.                          <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  This tool creates new files or replaces entire file contents. Use for initial file creation or complete        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  rewrites. Files are stored persistently in agent state.                                                        <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Parameters:                                                                                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - file_path (required): Path where the file should be created/overwritten                                      <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  - content (required): The complete content to write to the file                                                <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  Important: This replaces the entire file content.                                                              <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Create a new file or completely overwrite an existing file in the virtual filesystem.                          \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  This tool creates new files or replaces entire file contents. Use for initial file creation or complete        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  rewrites. Files are stored persistently in agent state.                                                        \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Parameters:                                                                                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - file_path (required): Path where the file should be created/overwritten                                      \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  - content (required): The complete content to write to the file                                                \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  Important: This replaces the entire file content.                                                              \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_prompt(WRITE_FILE_DESCRIPTION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d581826",
   "metadata": {},
   "source": [
    "Let's implement these functions below. There are two items worth noting. The first is the use of `@tool(description=PROMPT)`. Note that when `description=\"xyz\" is in the tool decorator, \"xyz\" is sent to the LLM and the docstring is suppressed. It is often more convenient to have lengthy descriptions in a separate prompts file. This provides space to explain both the operation of the tool and how it should be used in this application. The second item is the error messages. These messages are intended for the LLM vs a human user. In an agentic system, the LLM can use the information in error messages to retry the operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b7f3968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/deep_agents_from_scratch/file_tools.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/deep_agents_from_scratch/file_tools.py\n",
    "\"\"\"Virtual file system tools for agent state management.\n",
    "\n",
    "This module provides tools for managing a virtual filesystem stored in agent state,\n",
    "enabling context offloading and information persistence across agent interactions.\n",
    "\"\"\"\n",
    "\n",
    "from typing import Annotated\n",
    "\n",
    "from langchain_core.messages import ToolMessage\n",
    "from langchain_core.tools import InjectedToolCallId, tool\n",
    "from langgraph.prebuilt import InjectedState\n",
    "from langgraph.types import Command\n",
    "\n",
    "from deep_agents_from_scratch.prompts import (\n",
    "    LS_DESCRIPTION,\n",
    "    READ_FILE_DESCRIPTION,\n",
    "    WRITE_FILE_DESCRIPTION,\n",
    ")\n",
    "from deep_agents_from_scratch.state import DeepAgentState\n",
    "\n",
    "\n",
    "@tool(description=LS_DESCRIPTION)\n",
    "def ls(state: Annotated[DeepAgentState, InjectedState]) -> list[str]:\n",
    "    \"\"\"List all files in the virtual filesystem.\"\"\"\n",
    "    return list(state.get(\"files\", {}).keys())\n",
    "\n",
    "\n",
    "@tool(description=READ_FILE_DESCRIPTION, parse_docstring=True)\n",
    "def read_file(\n",
    "    file_path: str,\n",
    "    state: Annotated[DeepAgentState, InjectedState],\n",
    "    offset: int = 0,\n",
    "    limit: int = 2000,\n",
    ") -> str:\n",
    "    \"\"\"Read file content from virtual filesystem with optional offset and limit.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path to the file to read\n",
    "        state: Agent state containing virtual filesystem (injected in tool node)\n",
    "        offset: Line number to start reading from (default: 0)\n",
    "        limit: Maximum number of lines to read (default: 2000)\n",
    "\n",
    "    Returns:\n",
    "        Formatted file content with line numbers, or error message if file not found\n",
    "    \"\"\"\n",
    "    files = state.get(\"files\", {})\n",
    "    if file_path not in files:\n",
    "        return f\"Error: File '{file_path}' not found\"\n",
    "\n",
    "    content = files[file_path]\n",
    "    if not content:\n",
    "        return \"System reminder: File exists but has empty contents\"\n",
    "\n",
    "    lines = content.splitlines()\n",
    "    start_idx = offset\n",
    "    end_idx = min(start_idx + limit, len(lines))\n",
    "\n",
    "    if start_idx >= len(lines):\n",
    "        return f\"Error: Line offset {offset} exceeds file length ({len(lines)} lines)\"\n",
    "\n",
    "    result_lines = []\n",
    "    for i in range(start_idx, end_idx):\n",
    "        line_content = lines[i][:2000]  # Truncate long lines\n",
    "        result_lines.append(f\"{i + 1:6d}\\t{line_content}\")\n",
    "\n",
    "    return \"\\n\".join(result_lines)\n",
    "\n",
    "\n",
    "@tool(description=WRITE_FILE_DESCRIPTION, parse_docstring=True)\n",
    "def write_file(\n",
    "    file_path: str,\n",
    "    content: str,\n",
    "    state: Annotated[DeepAgentState, InjectedState],\n",
    "    tool_call_id: Annotated[str, InjectedToolCallId],\n",
    ") -> Command:\n",
    "    \"\"\"Write content to a file in the virtual filesystem.\n",
    "\n",
    "    Args:\n",
    "        file_path: Path where the file should be created/updated\n",
    "        content: Content to write to the file\n",
    "        state: Agent state containing virtual filesystem (injected in tool node)\n",
    "        tool_call_id: Tool call identifier for message response (injected in tool node)\n",
    "\n",
    "    Returns:\n",
    "        Command to update agent state with new file content\n",
    "    \"\"\"\n",
    "    files = state.get(\"files\", {})\n",
    "    files[file_path] = content\n",
    "    return Command(\n",
    "        update={\n",
    "            \"files\": files,\n",
    "            \"messages\": [\n",
    "                ToolMessage(f\"Updated file {file_path}\", tool_call_id=tool_call_id)\n",
    "            ],\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d557741d-20c4-434e-b565-0dfd2729f7af",
   "metadata": {},
   "source": [
    "# Revisiting state and reducer \n",
    "In the previous notebook, we defined the file state and reducer, but did not describe them. Let's do that here.\n",
    "In `DeepAgentState`, `files` is defined as a dictionary with a key and value. As was mentioned above, the key is the filename and the value is the content of the file. `files` are added to state using the `file_reducer` when the `Command` in `write_files` is executed. In this reducer, `left` is the existing files in state and `right` is new values. The final statement allows the new values to overwrite old values: `{**left, **right}`, Python unpacks `left` first, then `right`. Any duplicate keys from `right` overwrite the earlier values from `left`.\n",
    "\n",
    "```python\n",
    "def file_reducer(left, right):\n",
    "    \"\"\"Merge two file dictionaries, with right side taking precedence.\n",
    "\n",
    "    Used as a reducer function for the files field in agent state,\n",
    "    allowing incremental updates to the virtual file system.\n",
    "\n",
    "    Args:\n",
    "        left: Left side dictionary (existing files)\n",
    "        right: Right side dictionary (new/updated files)\n",
    "\n",
    "    Returns:\n",
    "        Merged dictionary with right values overriding left values\n",
    "    \"\"\"\n",
    "    if left is None:\n",
    "        return right\n",
    "    elif right is None:\n",
    "        return left\n",
    "    else:\n",
    "        return {**left, **right}\n",
    "\n",
    "\n",
    "class DeepAgentState(AgentState):\n",
    "    \"\"\"Extended agent state that includes task tracking and virtual file system.\n",
    "\n",
    "    Inherits from LangGraph's AgentState and adds:\n",
    "    - todos: List of Todo items for task planning and progress tracking\n",
    "    - files: Virtual file system stored as dict mapping filenames to content\n",
    "    \"\"\"\n",
    "\n",
    "    todos: NotRequired[list[Todo]]\n",
    "    files: Annotated[NotRequired[dict[str, str]], file_reducer]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0a899",
   "metadata": {},
   "source": [
    "We have a virtual filesystem and tools to work with it.  Let's build a simple research agent to try it out. \n",
    "The agent will store the user's request and then read it back before answering the user's question! \n",
    "\n",
    "Note that this simple approach is [very useful with long-running agent trajectories](https://www.anthropic.com/engineering/multi-agent-research-system#:~:text=Long%2Dhorizon%20conversation,across%20extended%20interactions.)! In this simple example, all information is easily kept in context, but for long-running agents, context content can be compressed or eliminated. Storing information prior to compression and retrieving it when it's needed is smart context engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6a1ac50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭──────────────────────────────────────────────────── </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">Prompt</span><span style=\"color: #000080; text-decoration-color: #000080\"> ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  You have access to a virtual file system to help you retain and save context.                                  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">## Workflow Process                                                                                          </span>  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  1. **Orient**: Use the ls() tool to see existing files before starting work                                    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  2. **Save**: Use the write_file() tool to store the user's request so that we can keep it for later            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  3. **Read**: Once you are satisfied with the collected sources, read the saved file and use it to ensure that  <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  you directly answer the user's question.                                                                       <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  ================================================================================                               <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  IMPORTANT: Just make a single call to the web_search tool and use the result provided by the tool to answer    <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>  the user's question.                                                                                           <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span>                                                                                                                 <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m \u001b[0m\u001b[1;32mPrompt\u001b[0m\u001b[34m \u001b[0m\u001b[34m────────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  You have access to a virtual file system to help you retain and save context.                                  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  \u001b[1;35m## Workflow Process                                                                                          \u001b[0m  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  1. **Orient**: Use the ls() tool to see existing files before starting work                                    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  2. **Save**: Use the write_file() tool to store the user's request so that we can keep it for later            \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  3. **Read**: Once you are satisfied with the collected sources, read the saved file and use it to ensure that  \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  you directly answer the user's question.                                                                       \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  ================================================================================                               \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  IMPORTANT: Just make a single call to the web_search tool and use the result provided by the tool to answer    \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m  the user's question.                                                                                           \u001b[34m│\u001b[0m\n",
       "\u001b[34m│\u001b[0m                                                                                                                 \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# File usage instructions\n",
    "FILE_USAGE_INSTRUCTIONS = \"\"\"You have access to a virtual file system to help you retain and save context.                                  \n",
    "                                                                                                                \n",
    "## Workflow Process                                                                                            \n",
    "1. **Orient**: Use the ls() tool to see existing files before starting work                                             \n",
    "2. **Save**: Use the write_file() tool to store the user's request so that we can keep it for later                     \n",
    "3. **Read**: Once you are satisfied with the collected sources, read the saved file and use it to ensure that you directly answer the user's question.\"\"\"\n",
    "\n",
    "# Add mock research instructions\n",
    "SIMPLE_RESEARCH_INSTRUCTIONS = \"\"\"IMPORTANT: Just make a single call to the web_search tool and use the result provided by the tool to answer the user's question.\"\"\"\n",
    "\n",
    "# Full prompt\n",
    "INSTRUCTIONS = (\n",
    "    FILE_USAGE_INSTRUCTIONS + \"\\n\\n\" + \"=\" * 80 + \"\\n\\n\" + SIMPLE_RESEARCH_INSTRUCTIONS\n",
    ")\n",
    "show_prompt(INSTRUCTIONS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a94f78c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_sambanova import ChatSambaNova\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "from utils import format_messages\n",
    "\n",
    "from deep_agents_from_scratch.file_tools import ls, read_file, write_file\n",
    "from deep_agents_from_scratch.state import DeepAgentState\n",
    "\n",
    "# Mock search result\n",
    "search_result = \"\"\"The Model Context Protocol (MCP) is an open standard protocol developed \n",
    "by Anthropic to enable seamless integration between AI models and external systems like \n",
    "tools, databases, and other services. It acts as a standardized communication layer, \n",
    "allowing AI models to access and utilize data from various sources in a consistent and \n",
    "efficient manner. Essentially, MCP simplifies the process of connecting AI assistants \n",
    "to external services by providing a unified language for data exchange. \"\"\"\n",
    "\n",
    "\n",
    "# Mock search tool\n",
    "@tool(parse_docstring=True)\n",
    "def web_search(\n",
    "    query: str,\n",
    "):\n",
    "    \"\"\"Search the web for information on a specific topic.\n",
    "\n",
    "    This tool performs web searches and returns relevant results\n",
    "    for the given query. Use this when you need to gather information from\n",
    "    the internet about any topic.\n",
    "\n",
    "    Args:\n",
    "        query: The search query string. Be specific and clear about what\n",
    "               information you're looking for.\n",
    "\n",
    "    Returns:\n",
    "        Search results from search engine.\n",
    "\n",
    "    Example:\n",
    "        web_search(\"machine learning applications in healthcare\")\n",
    "    \"\"\"\n",
    "    return search_result\n",
    "\n",
    "\n",
    "# Create agent using create_react_agent directly\n",
    "#model = init_chat_model(model=\"anthropic:claude-sonnet-4-20250514\", temperature=0.0)\n",
    "model = ChatSambaNova(model=\"DeepSeek-V3.1\", temperature=0.0)\n",
    "tools = [ls, read_file, write_file, web_search]\n",
    "\n",
    "# Create agent with system prompt\n",
    "agent = create_react_agent(\n",
    "    model, tools, prompt=INSTRUCTIONS, state_schema=DeepAgentState\n",
    ")\n",
    "\n",
    "# Show the agent\n",
    "display(Image(agent.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7054ebcc",
   "metadata": {},
   "source": [
    "Start the graph with no `files` in state and an user research request. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c3e90ac0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080\">╭─────────────────────────────────────────────────── 🧑 Human ────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">│</span> Give me an overview of Model Context Protocol (MCP).                                                            <span style=\"color: #000080; text-decoration-color: #000080\">│</span>\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[34m╭─\u001b[0m\u001b[34m──────────────────────────────────────────────────\u001b[0m\u001b[34m 🧑 Human \u001b[0m\u001b[34m───────────────────────────────────────────────────\u001b[0m\u001b[34m─╮\u001b[0m\n",
       "\u001b[34m│\u001b[0m Give me an overview of Model Context Protocol (MCP).                                                            \u001b[34m│\u001b[0m\n",
       "\u001b[34m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: web_search                                                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"query\": \"Model Context Protocol MCP overview what is it how does it work\"                                    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: call_e0430a6184a74d0a87                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: web_search                                                                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"query\": \"Model Context Protocol MCP overview what is it how does it work\"                                    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: call_e0430a6184a74d0a87                                                                                  \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The Model Context Protocol (MCP) is an open standard protocol developed                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> by Anthropic to enable seamless integration between AI models and external systems like                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> tools, databases, and other services. It acts as a standardized communication layer,                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> allowing AI models to access and utilize data from various sources in a consistent and                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> efficient manner. Essentially, MCP simplifies the process of connecting AI assistants                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> to external services by providing a unified language for data exchange.                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m The Model Context Protocol (MCP) is an open standard protocol developed                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m by Anthropic to enable seamless integration between AI models and external systems like                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m tools, databases, and other services. It acts as a standardized communication layer,                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m allowing AI models to access and utilize data from various sources in a consistent and                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m efficient manner. Essentially, MCP simplifies the process of connecting AI assistants                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m to external services by providing a unified language for data exchange.                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: write_file                                                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"content\": \"User request: Give me an overview of Model Context Protocol (MCP)\",                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"file_path\": \"mcp_overview_request.txt\"                                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: call_be33b0cba6944bbcbd                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: write_file                                                                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"content\": \"User request: Give me an overview of Model Context Protocol (MCP)\",                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"file_path\": \"mcp_overview_request.txt\"                                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: call_be33b0cba6944bbcbd                                                                                  \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> Updated file mcp_overview_request.txt                                                                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m Updated file mcp_overview_request.txt                                                                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> 🔧 Tool Call: web_search                                                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    Args: {                                                                                                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>   \"query\": \"Model Context Protocol MCP Anthropic features architecture benefits use cases\"                      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> }                                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>    ID: call_f005ec0931af42e294                                                                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m 🔧 Tool Call: web_search                                                                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    Args: {                                                                                                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m   \"query\": \"Model Context Protocol MCP Anthropic features architecture benefits use cases\"                      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m }                                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m    ID: call_f005ec0931af42e294                                                                                  \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000\">╭──────────────────────────────────────────────── 🔧 Tool Output ─────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> The Model Context Protocol (MCP) is an open standard protocol developed                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> by Anthropic to enable seamless integration between AI models and external systems like                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> tools, databases, and other services. It acts as a standardized communication layer,                            <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> allowing AI models to access and utilize data from various sources in a consistent and                          <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> efficient manner. Essentially, MCP simplifies the process of connecting AI assistants                           <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">│</span> to external services by providing a unified language for data exchange.                                         <span style=\"color: #808000; text-decoration-color: #808000\">│</span>\n",
       "<span style=\"color: #808000; text-decoration-color: #808000\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[33m╭─\u001b[0m\u001b[33m───────────────────────────────────────────────\u001b[0m\u001b[33m 🔧 Tool Output \u001b[0m\u001b[33m────────────────────────────────────────────────\u001b[0m\u001b[33m─╮\u001b[0m\n",
       "\u001b[33m│\u001b[0m The Model Context Protocol (MCP) is an open standard protocol developed                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m by Anthropic to enable seamless integration between AI models and external systems like                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m tools, databases, and other services. It acts as a standardized communication layer,                            \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m allowing AI models to access and utilize data from various sources in a consistent and                          \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m efficient manner. Essentially, MCP simplifies the process of connecting AI assistants                           \u001b[33m│\u001b[0m\n",
       "\u001b[33m│\u001b[0m to external services by providing a unified language for data exchange.                                         \u001b[33m│\u001b[0m\n",
       "\u001b[33m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╭───────────────────────────────────────────────────── 📝 AI ─────────────────────────────────────────────────────╮</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> Based on my search results, here's an overview of the Model Context Protocol (MCP):                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> ## Model Context Protocol (MCP) Overview                                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> **What is MCP?**                                                                                                <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> The Model Context Protocol (MCP) is an open standard protocol developed by Anthropic that enables seamless      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> integration between AI models and external systems. It serves as a standardized communication layer that allows <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> AI models to access and utilize data from various external sources.                                             <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> **Key Features and Purpose:**                                                                                   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - **Standardized Integration**: Provides a unified language for data exchange between AI models and external    <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> services                                                                                                        <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - **Seamless Connectivity**: Enables AI models to connect to tools, databases, and other services               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - **Efficient Data Access**: Allows AI assistants to access and utilize data from multiple sources consistently <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - **Simplified Process**: Makes it easier to connect AI systems to external services and resources              <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> **How It Works:**                                                                                               <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> MCP acts as a communication bridge that standardizes how AI models interact with external systems. Instead of   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> each AI model needing custom integration code for different services, MCP provides a common protocol that       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> handles the communication, making it easier to connect AI assistants to various data sources and tools.         <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> **Benefits:**                                                                                                   <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Reduces development complexity for AI integrations                                                            <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Enables consistent access to external data and services                                                       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Supports interoperability between different AI systems and external resources                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> - Facilitates the creation of more capable AI assistants that can leverage external tools and information       <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>                                                                                                                 <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> MCP represents an important step in making AI systems more capable by providing standardized access to the      <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span> broader ecosystem of tools and data sources they need to function effectively.                                  <span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">│</span>\n",
       "<span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37m╭─\u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m 📝 AI \u001b[0m\u001b[37m────────────────────────────────────────────────────\u001b[0m\u001b[37m─╮\u001b[0m\n",
       "\u001b[37m│\u001b[0m Based on my search results, here's an overview of the Model Context Protocol (MCP):                             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m ## Model Context Protocol (MCP) Overview                                                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m **What is MCP?**                                                                                                \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m The Model Context Protocol (MCP) is an open standard protocol developed by Anthropic that enables seamless      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m integration between AI models and external systems. It serves as a standardized communication layer that allows \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m AI models to access and utilize data from various external sources.                                             \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m **Key Features and Purpose:**                                                                                   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - **Standardized Integration**: Provides a unified language for data exchange between AI models and external    \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m services                                                                                                        \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - **Seamless Connectivity**: Enables AI models to connect to tools, databases, and other services               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - **Efficient Data Access**: Allows AI assistants to access and utilize data from multiple sources consistently \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - **Simplified Process**: Makes it easier to connect AI systems to external services and resources              \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m **How It Works:**                                                                                               \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m MCP acts as a communication bridge that standardizes how AI models interact with external systems. Instead of   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m each AI model needing custom integration code for different services, MCP provides a common protocol that       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m handles the communication, making it easier to connect AI assistants to various data sources and tools.         \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m **Benefits:**                                                                                                   \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - Reduces development complexity for AI integrations                                                            \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - Enables consistent access to external data and services                                                       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - Supports interoperability between different AI systems and external resources                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m - Facilitates the creation of more capable AI assistants that can leverage external tools and information       \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m                                                                                                                 \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m MCP represents an important step in making AI systems more capable by providing standardized access to the      \u001b[37m│\u001b[0m\n",
       "\u001b[37m│\u001b[0m broader ecosystem of tools and data sources they need to function effectively.                                  \u001b[37m│\u001b[0m\n",
       "\u001b[37m╰─────────────────────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Give me an overview of Model Context Protocol (MCP).\",\n",
    "            }\n",
    "        ],\n",
    "        \"files\": {},\n",
    "    }\n",
    ")\n",
    "format_messages(result[\"messages\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4addd08d",
   "metadata": {},
   "source": [
    "We can see the file saved in our mock file system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "449c8ecd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mcp_overview_request.txt': 'User request: Give me an overview of Model Context Protocol (MCP)'}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"files\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbb506b",
   "metadata": {},
   "source": [
    "Trace: \n",
    "https://smith.langchain.com/public/b03e20b4-e908-488d-84a9-8f891d17addd/r\n",
    "<!-- https://smith.langchain.com/public/1066102f-d7b3-423c-b556-006865a1d479/r -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f4ec9b-6dd5-43cf-a0ee-274b0b638c01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
